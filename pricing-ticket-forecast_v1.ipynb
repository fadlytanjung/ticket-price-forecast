{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a83ddfd-8862-4289-9a78-d7f2df83678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline\n",
    "from pytorch_forecasting.data import NaNLabelEncoder, GroupNormalizer\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410effa3-a31d-4874-8ec6-3265a6538984",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f67c8e-94a2-411a-876d-d65b3ff8074e",
   "metadata": {},
   "source": [
    "#### Load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbeb271-2d57-4f38-988b-67238ee086c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>extract_timestamp</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>depart_date</th>\n",
       "      <th>best_price</th>\n",
       "      <th>airport_from</th>\n",
       "      <th>airport_to</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>flight_time_hour</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>calendar_day</th>\n",
       "      <th>calendar_year</th>\n",
       "      <th>calendar_month</th>\n",
       "      <th>week_number</th>\n",
       "      <th>extraction_period</th>\n",
       "      <th>route</th>\n",
       "      <th>days_to_departure</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30078</td>\n",
       "      <td>2022-12-29 03:13:11.798742</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1414200.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>3 days</td>\n",
       "      <td>CGK_BDJ</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30232</td>\n",
       "      <td>2022-12-31 01:49:22.466131</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1137800.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1 days</td>\n",
       "      <td>CGK_BDJ</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30077</td>\n",
       "      <td>2022-12-29 03:13:11.798742</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1345400.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4 days</td>\n",
       "      <td>CGK_BDJ</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30235</td>\n",
       "      <td>2022-12-31 01:49:22.466131</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1206600.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2 days</td>\n",
       "      <td>CGK_BDJ</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30438</td>\n",
       "      <td>2023-01-02 00:37:44.519977</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1348099.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>BDJ</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days</td>\n",
       "      <td>CGK_BDJ</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45390</th>\n",
       "      <td>10995</td>\n",
       "      <td>2023-02-01 22:44:34.976945</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>YIA</td>\n",
       "      <td>2023-07-29</td>\n",
       "      <td>495660.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>YIA</td>\n",
       "      <td>455.91</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>29</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>178 days</td>\n",
       "      <td>CGK_YIA</td>\n",
       "      <td>178</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45391</th>\n",
       "      <td>10807</td>\n",
       "      <td>2023-02-01 09:17:51.827188</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>YIA</td>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>475660.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>YIA</td>\n",
       "      <td>455.91</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>179 days</td>\n",
       "      <td>CGK_YIA</td>\n",
       "      <td>179</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45392</th>\n",
       "      <td>10987</td>\n",
       "      <td>2023-02-01 22:44:34.976945</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>YIA</td>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>495660.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>YIA</td>\n",
       "      <td>455.91</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>179 days</td>\n",
       "      <td>CGK_YIA</td>\n",
       "      <td>179</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45393</th>\n",
       "      <td>10809</td>\n",
       "      <td>2023-02-01 09:17:51.827188</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>YIA</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>475660.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>YIA</td>\n",
       "      <td>455.91</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>31</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>180 days</td>\n",
       "      <td>CGK_YIA</td>\n",
       "      <td>180</td>\n",
       "      <td>Monday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45394</th>\n",
       "      <td>10989</td>\n",
       "      <td>2023-02-01 22:44:34.976945</td>\n",
       "      <td>JKTC</td>\n",
       "      <td>YIA</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>495660.0</td>\n",
       "      <td>CGK</td>\n",
       "      <td>YIA</td>\n",
       "      <td>455.91</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>31</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>180 days</td>\n",
       "      <td>CGK_YIA</td>\n",
       "      <td>180</td>\n",
       "      <td>Monday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45395 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           extract_timestamp origin destination depart_date  \\\n",
       "0           30078  2022-12-29 03:13:11.798742   JKTC         BDJ  2023-01-01   \n",
       "1           30232  2022-12-31 01:49:22.466131   JKTC         BDJ  2023-01-01   \n",
       "2           30077  2022-12-29 03:13:11.798742   JKTC         BDJ  2023-01-02   \n",
       "3           30235  2022-12-31 01:49:22.466131   JKTC         BDJ  2023-01-02   \n",
       "4           30438  2023-01-02 00:37:44.519977   JKTC         BDJ  2023-01-02   \n",
       "...           ...                         ...    ...         ...         ...   \n",
       "45390       10995  2023-02-01 22:44:34.976945   JKTC         YIA  2023-07-29   \n",
       "45391       10807  2023-02-01 09:17:51.827188   JKTC         YIA  2023-07-30   \n",
       "45392       10987  2023-02-01 22:44:34.976945   JKTC         YIA  2023-07-30   \n",
       "45393       10809  2023-02-01 09:17:51.827188   JKTC         YIA  2023-07-31   \n",
       "45394       10989  2023-02-01 22:44:34.976945   JKTC         YIA  2023-07-31   \n",
       "\n",
       "       best_price airport_from airport_to  distance_km  flight_time_hour  ...  \\\n",
       "0       1414200.0          CGK        BDJ       946.44              2.02  ...   \n",
       "1       1137800.0          CGK        BDJ       946.44              2.02  ...   \n",
       "2       1345400.0          CGK        BDJ       946.44              2.02  ...   \n",
       "3       1206600.0          CGK        BDJ       946.44              2.02  ...   \n",
       "4       1348099.0          CGK        BDJ       946.44              2.02  ...   \n",
       "...           ...          ...        ...          ...               ...  ...   \n",
       "45390    495660.0          CGK        YIA       455.91              1.33  ...   \n",
       "45391    475660.0          CGK        YIA       455.91              1.33  ...   \n",
       "45392    495660.0          CGK        YIA       455.91              1.33  ...   \n",
       "45393    475660.0          CGK        YIA       455.91              1.33  ...   \n",
       "45394    495660.0          CGK        YIA       455.91              1.33  ...   \n",
       "\n",
       "      weekday_name calendar_day calendar_year  calendar_month  week_number  \\\n",
       "0           Sunday            1          2023               1           52   \n",
       "1           Sunday            1          2023               1           52   \n",
       "2           Monday            2          2023               1            1   \n",
       "3           Monday            2          2023               1            1   \n",
       "4           Monday            2          2023               1            1   \n",
       "...            ...          ...           ...             ...          ...   \n",
       "45390     Saturday           29          2023               7           30   \n",
       "45391       Sunday           30          2023               7           30   \n",
       "45392       Sunday           30          2023               7           30   \n",
       "45393       Monday           31          2023               7           31   \n",
       "45394       Monday           31          2023               7           31   \n",
       "\n",
       "       extraction_period    route days_to_departure   weekday    month  \n",
       "0                 3 days  CGK_BDJ                 3    Sunday  January  \n",
       "1                 1 days  CGK_BDJ                 1    Sunday  January  \n",
       "2                 4 days  CGK_BDJ                 4    Monday  January  \n",
       "3                 2 days  CGK_BDJ                 2    Monday  January  \n",
       "4                 0 days  CGK_BDJ                 0    Monday  January  \n",
       "...                  ...      ...               ...       ...      ...  \n",
       "45390           178 days  CGK_YIA               178  Saturday     July  \n",
       "45391           179 days  CGK_YIA               179    Sunday     July  \n",
       "45392           179 days  CGK_YIA               179    Sunday     July  \n",
       "45393           180 days  CGK_YIA               180    Monday     July  \n",
       "45394           180 days  CGK_YIA               180    Monday     July  \n",
       "\n",
       "[45395 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your full dataset\n",
    "df = pd.read_csv(\"ticket_price_dist.csv\")\n",
    "\n",
    "# Ensure dates are in datetime format\n",
    "df[\"depart_date\"] = pd.to_datetime(df[\"depart_date\"])\n",
    "df[\"extract_date\"] = pd.to_datetime(df[\"extract_date\"])\n",
    "df['route'] = df['airport_from'] + \"_\" + df['airport_to']\n",
    "\n",
    "# Optional: days to departure as a known future feature\n",
    "df[\"days_to_departure\"] = (df[\"depart_date\"] - df[\"extract_date\"]).dt.days\n",
    "\n",
    "df[\"weekday\"] = df[\"depart_date\"].dt.day_name()\n",
    "df[\"month\"] = df[\"depart_date\"].dt.month_name()\n",
    "\n",
    "df[\"weekday\"] = df[\"weekday\"].astype(\"category\")\n",
    "df[\"month\"] = df[\"month\"].astype(\"category\")\n",
    "\n",
    "# Encode route as category\n",
    "df[\"route\"] = df[\"route\"].astype(\"category\")\n",
    "df = df.sort_values(['route', 'depart_date']).reset_index(drop=True)\n",
    "\n",
    "# Drop missing prices\n",
    "df = df.dropna(subset=[\"best_price\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a60c2-549f-4ecd-bb26-ca9e04ecc89b",
   "metadata": {},
   "source": [
    "#### Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3f2969-dffe-4a36-8b9c-7107a8bb03fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 14\n",
    "max_prediction_length = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077b2a17-239e-4b82-8c97-89a1d67fcacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "route\n",
       "CGK_MKQ    198\n",
       "CGK_BIK    201\n",
       "CGK_BDO    208\n",
       "CGK_TRK    208\n",
       "CGK_TNJ    212\n",
       "CGK_TKG    212\n",
       "CGK_SUB    212\n",
       "CGK_SRG    212\n",
       "CGK_SOC    212\n",
       "CGK_PNK    212\n",
       "CGK_PLM    212\n",
       "CGK_PKU    212\n",
       "CGK_PGK    212\n",
       "CGK_PDG    212\n",
       "CGK_MLG    212\n",
       "CGK_BDJ    212\n",
       "CGK_MDC    212\n",
       "CGK_LOP    212\n",
       "CGK_KNO    212\n",
       "CGK_JOG    212\n",
       "CGK_DPS    212\n",
       "CGK_DJJ    212\n",
       "CGK_DJB    212\n",
       "CGK_BTJ    212\n",
       "CGK_BTH    212\n",
       "CGK_BPN    212\n",
       "CGK_BKS    212\n",
       "CGK_UPG    212\n",
       "CGK_YIA    212\n",
       "Name: depart_date, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cutoff = df[\"depart_date\"].max() - pd.Timedelta(days=max_prediction_length)\n",
    "df.groupby(\"route\")[\"depart_date\"].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc929e3-fe6a-4720-a879-9fb22c6f803b",
   "metadata": {},
   "source": [
    "#### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6f0750d-e6bf-421e-916a-c15c5bd95e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cutoff = df[\"depart_date\"].max() - pd.Timedelta(days=max_prediction_length)\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df[df[\"depart_date\"] <= training_cutoff],\n",
    "    time_idx=\"calendar_day\",\n",
    "    target=\"best_price\",\n",
    "    group_ids=[\"route\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"route\"],\n",
    "    time_varying_known_categoricals=[\"weekday\", \"month\"],\n",
    "    time_varying_known_reals=[\"days_to_departure\"],\n",
    "    time_varying_unknown_reals=[\"best_price\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"route\"], transformation=\"softplus\"),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    min_encoder_length=max_encoder_length,\n",
    ")\n",
    "\n",
    "# Validation\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=64, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31e6ca-9a1f-435d-864f-7cf0d5da5267",
   "metadata": {},
   "source": [
    "### Step 3: Preprocess & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03432922-2f1a-4b31-a254-a41ca55ee842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 389   \n",
      "3  | prescalers                         | ModuleDict                      | 96    \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.9 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 2.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.4 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "19.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.9 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|██████████▎                                                                                                      | 23/253 [00:38<06:20,  1.66s/it, loss=1.54e+05, v_num=3, train_loss_step=9.3e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "logger = CSVLogger(\"lightning_logs\", name=\"tft\")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=-1,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=0.1,\n",
    "    enable_model_summary=True,\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7713992-fe4e-4822-b238-5711db268eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"model_checkpoint_v2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f2beb77-643c-433b-b1d1-0572cdfa726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformer(\n",
       "  \t\"attention_head_size\":               1\n",
       "  \t\"categorical_groups\":                {}\n",
       "  \t\"causal_attention\":                  True\n",
       "  \t\"dropout\":                           0.1\n",
       "  \t\"embedding_labels\":                  {'route': {'CGK_BDJ': 0, 'CGK_BDO': 1, 'CGK_BIK': 2, 'CGK_BKS': 3, 'CGK_BPN': 4, 'CGK_BTH': 5, 'CGK_BTJ': 6, 'CGK_DJB': 7, 'CGK_DJJ': 8, 'CGK_DPS': 9, 'CGK_JOG': 10, 'CGK_KNO': 11, 'CGK_LOP': 12, 'CGK_MDC': 13, 'CGK_MKQ': 14, 'CGK_MLG': 15, 'CGK_PDG': 16, 'CGK_PGK': 17, 'CGK_PKU': 18, 'CGK_PLM': 19, 'CGK_PNK': 20, 'CGK_SOC': 21, 'CGK_SRG': 22, 'CGK_SUB': 23, 'CGK_TKG': 24, 'CGK_TNJ': 25, 'CGK_TRK': 26, 'CGK_UPG': 27, 'CGK_YIA': 28}, 'weekday': {'Friday': 0, 'Monday': 1, 'Saturday': 2, 'Sunday': 3, 'Thursday': 4, 'Tuesday': 5, 'Wednesday': 6}, 'month': {'April': 0, 'February': 1, 'January': 2, 'July': 3, 'June': 4, 'March': 5, 'May': 6}}\n",
       "  \t\"embedding_paddings\":                []\n",
       "  \t\"embedding_sizes\":                   {'route': (29, 11), 'weekday': (7, 5), 'month': (7, 5)}\n",
       "  \t\"hidden_continuous_size\":            8\n",
       "  \t\"hidden_continuous_sizes\":           {}\n",
       "  \t\"hidden_size\":                       16\n",
       "  \t\"learning_rate\":                     0.03\n",
       "  \t\"log_gradient_flow\":                 False\n",
       "  \t\"log_interval\":                      -1\n",
       "  \t\"log_val_interval\":                  -1\n",
       "  \t\"lstm_layers\":                       1\n",
       "  \t\"max_encoder_length\":                14\n",
       "  \t\"monotone_constaints\":               {}\n",
       "  \t\"optimizer\":                         ranger\n",
       "  \t\"optimizer_params\":                  None\n",
       "  \t\"output_size\":                       7\n",
       "  \t\"output_transformer\":                GroupNormalizer(\n",
       "  \t\tmethod='standard',\n",
       "  \t\tgroups=['route'],\n",
       "  \t\tcenter=True,\n",
       "  \t\tscale_by_group=False,\n",
       "  \t\ttransformation='softplus',\n",
       "  \t\tmethod_kwargs={}\n",
       "  \t)\n",
       "  \t\"reduce_on_plateau_min_lr\":          1e-05\n",
       "  \t\"reduce_on_plateau_patience\":        4\n",
       "  \t\"reduce_on_plateau_reduction\":       2.0\n",
       "  \t\"share_single_variable_networks\":    False\n",
       "  \t\"static_categoricals\":               ['route']\n",
       "  \t\"static_reals\":                      ['encoder_length', 'best_price_center', 'best_price_scale']\n",
       "  \t\"time_varying_categoricals_decoder\": ['weekday', 'month']\n",
       "  \t\"time_varying_categoricals_encoder\": ['weekday', 'month']\n",
       "  \t\"time_varying_reals_decoder\":        ['days_to_departure', 'relative_time_idx']\n",
       "  \t\"time_varying_reals_encoder\":        ['days_to_departure', 'relative_time_idx', 'best_price']\n",
       "  \t\"weight_decay\":                      0.0\n",
       "  \t\"x_categoricals\":                    ['route', 'weekday', 'month']\n",
       "  \t\"x_reals\":                           ['encoder_length', 'best_price_center', 'best_price_scale', 'days_to_departure', 'relative_time_idx', 'best_price']\n",
       "  (loss): QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
       "  (logging_metrics): ModuleList(\n",
       "    (0): SMAPE()\n",
       "    (1): MAE()\n",
       "    (2): RMSE()\n",
       "    (3): MAPE()\n",
       "  )\n",
       "  (input_embeddings): MultiEmbedding(\n",
       "    (embeddings): ModuleDict(\n",
       "      (route): Embedding(29, 11)\n",
       "      (weekday): Embedding(7, 5)\n",
       "      (month): Embedding(7, 5)\n",
       "    )\n",
       "  )\n",
       "  (prescalers): ModuleDict(\n",
       "    (encoder_length): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (best_price_center): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (best_price_scale): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (days_to_departure): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (relative_time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (best_price): Linear(in_features=1, out_features=8, bias=True)\n",
       "  )\n",
       "  (static_variable_selection): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (resample_norm): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=35, out_features=4, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=4, out_features=8, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleDict(\n",
       "      (route): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (encoder_length): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (best_price_center): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (best_price_scale): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (encoder_length): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (best_price_center): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (best_price_scale): Linear(in_features=1, out_features=8, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (encoder_variable_selection): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (resample_norm): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=34, out_features=5, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (context): Linear(in_features=16, out_features=5, bias=False)\n",
       "      (fc2): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=5, out_features=10, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleDict(\n",
       "      (weekday): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (month): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (days_to_departure): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_time_idx): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (best_price): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (days_to_departure): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (relative_time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (best_price): Linear(in_features=1, out_features=8, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (decoder_variable_selection): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (resample_norm): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=26, out_features=4, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (context): Linear(in_features=16, out_features=4, bias=False)\n",
       "      (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=4, out_features=8, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleDict(\n",
       "      (weekday): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (month): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (days_to_departure): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_time_idx): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (days_to_departure): Linear(in_features=1, out_features=8, bias=True)\n",
       "      (relative_time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (static_context_variable_selection): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (static_context_enrichment): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm_encoder): LSTM(16, 16, batch_first=True)\n",
       "  (lstm_decoder): LSTM(16, 16, batch_first=True)\n",
       "  (post_lstm_gate_encoder): GatedLinearUnit(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "  )\n",
       "  (post_lstm_gate_decoder): GatedLinearUnit(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "  )\n",
       "  (post_lstm_add_norm_encoder): AddNorm(\n",
       "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (post_lstm_add_norm_decoder): AddNorm(\n",
       "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (static_enrichment): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (context): Linear(in_features=16, out_features=16, bias=False)\n",
       "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (multihead_attn): InterpretableMultiHeadAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (v_layer): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (q_layers): ModuleList(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (k_layers): ModuleList(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (softmax): Softmax(dim=2)\n",
       "    )\n",
       "    (w_h): Linear(in_features=16, out_features=16, bias=False)\n",
       "  )\n",
       "  (post_attn_gate_norm): GateAddNorm(\n",
       "    (glu): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "    )\n",
       "    (add_norm): AddNorm(\n",
       "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pos_wise_ff): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_output_gate_norm): GateAddNorm(\n",
       "    (glu): GatedLinearUnit(\n",
       "      (fc): Linear(in_features=16, out_features=32, bias=True)\n",
       "    )\n",
       "    (add_norm): AddNorm(\n",
       "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=16, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# Load the model from checkpoint\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(\"model_checkpoint_v2.ckpt\", strict=False)\n",
    "tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b353a43-e141-4a0b-bc2c-1cecb4e8bc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(prediction=tensor([[[1685387.1250, 1714049.5000, 1715069.5000,  ..., 1720715.6250,\n",
       "          1727055.6250, 1738461.0000],\n",
       "         [1680097.1250, 1709594.8750, 1711121.0000,  ..., 1716386.2500,\n",
       "          1721814.5000, 1735234.7500],\n",
       "         [1120225.8750, 1140477.7500, 1152882.2500,  ..., 1170817.8750,\n",
       "          1183941.2500, 1201140.8750],\n",
       "         ...,\n",
       "         [1055876.0000, 1065794.0000, 1072573.5000,  ..., 1081937.1250,\n",
       "          1088098.5000, 1099684.7500],\n",
       "         [1054190.1250, 1067156.6250, 1075466.6250,  ..., 1087288.0000,\n",
       "          1095221.2500, 1109225.3750],\n",
       "         [1199799.0000, 1213622.7500, 1222238.3750,  ..., 1240516.2500,\n",
       "          1252505.6250, 1265446.0000]],\n",
       "\n",
       "        [[2314097.2500, 2338145.7500, 2355075.2500,  ..., 2384331.7500,\n",
       "          2402361.2500, 2423334.0000],\n",
       "         [2317056.5000, 2338808.5000, 2354875.2500,  ..., 2381410.0000,\n",
       "          2397257.0000, 2416280.2500],\n",
       "         [2322175.7500, 2344325.0000, 2360669.7500,  ..., 2386514.2500,\n",
       "          2401650.7500, 2420128.5000],\n",
       "         ...,\n",
       "         [2029271.1250, 2057601.1250, 2081324.2500,  ..., 2109267.7500,\n",
       "          2119828.0000, 2149145.0000],\n",
       "         [2017281.5000, 2048593.3750, 2074370.0000,  ..., 2105261.2500,\n",
       "          2117952.5000, 2149798.5000],\n",
       "         [2093062.5000, 2159104.7500, 2197706.5000,  ..., 2271910.7500,\n",
       "          2319499.5000, 2393255.0000]],\n",
       "\n",
       "        [[2826637.0000, 2863661.0000, 2894839.5000,  ..., 2955162.5000,\n",
       "          2991334.7500, 3049793.5000],\n",
       "         [2838994.0000, 2867277.2500, 2894640.5000,  ..., 2946725.0000,\n",
       "          2977391.7500, 3026788.2500],\n",
       "         [2852494.5000, 2875699.5000, 2900504.0000,  ..., 2945815.0000,\n",
       "          2972038.0000, 3015160.2500],\n",
       "         ...,\n",
       "         [4211087.5000, 4234169.5000, 4242102.5000,  ..., 4258273.5000,\n",
       "          4265613.0000, 4288329.0000],\n",
       "         [4211309.0000, 4235193.5000, 4243191.5000,  ..., 4259018.0000,\n",
       "          4265995.5000, 4287384.0000],\n",
       "         [2766458.0000, 2799662.0000, 2829119.0000,  ..., 2884191.0000,\n",
       "          2917608.7500, 2974150.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2181847.2500, 2211219.2500, 2226330.5000,  ..., 2257106.0000,\n",
       "          2277809.5000, 2305925.0000],\n",
       "         [2151064.5000, 2164663.5000, 2172315.0000,  ..., 2185607.5000,\n",
       "          2194593.2500, 2206993.2500],\n",
       "         [2192182.2500, 2198988.2500, 2202623.7500,  ..., 2208671.5000,\n",
       "          2212624.2500, 2216906.0000],\n",
       "         ...,\n",
       "         [2184804.5000, 2191244.2500, 2194971.2500,  ..., 2201575.5000,\n",
       "          2206229.5000, 2211201.7500],\n",
       "         [2184723.5000, 2191673.2500, 2195629.0000,  ..., 2202653.7500,\n",
       "          2207659.0000, 2213005.2500],\n",
       "         [2072684.7500, 2083251.1250, 2089513.5000,  ..., 2102043.5000,\n",
       "          2110395.0000, 2120326.7500]],\n",
       "\n",
       "        [[1718476.5000, 1747677.0000, 1753060.0000,  ..., 1765403.8750,\n",
       "          1774057.0000, 1791543.6250],\n",
       "         [1717680.7500, 1746437.8750, 1751966.5000,  ..., 1763522.6250,\n",
       "          1771129.7500, 1789338.7500],\n",
       "         [1513625.8750, 1522422.6250, 1526713.1250,  ..., 1534180.3750,\n",
       "          1538872.7500, 1545357.3750],\n",
       "         ...,\n",
       "         [1481399.8750, 1492444.0000, 1498787.6250,  ..., 1510261.8750,\n",
       "          1518418.8750, 1528214.3750],\n",
       "         [1483395.3750, 1495544.2500, 1502367.7500,  ..., 1514692.3750,\n",
       "          1523549.1250, 1534157.7500],\n",
       "         [1230823.5000, 1248279.5000, 1259289.5000,  ..., 1279971.1250,\n",
       "          1293666.7500, 1312016.7500]],\n",
       "\n",
       "        [[ 667710.3750,  680796.0000,  686162.4375,  ...,  697306.5625,\n",
       "           705711.2500,  717370.2500],\n",
       "         [ 638980.8125,  652390.6875,  658872.5000,  ...,  670484.8750,\n",
       "           678674.3125,  692278.0000],\n",
       "         [ 615281.8750,  619894.5625,  622540.0625,  ...,  627320.5625,\n",
       "           631230.0625,  635571.9375],\n",
       "         ...,\n",
       "         [ 607788.0625,  613064.2500,  616211.1250,  ...,  622023.6250,\n",
       "           626618.3750,  632377.8750],\n",
       "         [ 605759.0000,  612286.2500,  616069.5000,  ...,  622885.1250,\n",
       "           628131.4375,  635269.3750],\n",
       "         [ 473155.0312,  492081.0000,  503488.4062,  ...,  524721.0000,\n",
       "           538117.5000,  560589.6250]]]), encoder_attention=tensor([[[[1.6954e-04, 4.3696e-06, 3.2030e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.8961e-04, 5.5398e-06, 4.1045e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[8.8287e-05, 8.0377e-07, 8.0543e-07,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.4492e-07, 4.0999e-08, 4.8044e-08,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.7817e-07, 3.9981e-08, 4.7331e-08,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.5023e-06, 7.1853e-06, 4.1215e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[9.5778e-05, 1.6017e-04, 2.8676e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.0309e-04, 1.5725e-04, 3.3970e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.4741e-04, 2.1352e-04, 5.4386e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.0404e-05, 2.9587e-06, 2.9244e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.0267e-05, 4.7210e-06, 3.4319e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.0273e-07, 1.1254e-03, 1.3826e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[1.2357e-06, 1.8632e-06, 2.5205e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[9.8702e-07, 7.6711e-07, 7.2605e-07,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.3369e-06, 1.3618e-06, 1.2960e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.6190e-03, 7.9215e-04, 5.3876e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[4.6134e-03, 8.6518e-04, 5.3238e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.2457e-07, 4.5763e-07, 7.9153e-07,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1.1010e-04, 5.7878e-05, 2.0252e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.6472e-04, 2.8249e-04, 3.8968e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.2136e-05, 3.4480e-05, 5.3391e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.6780e-06, 5.2069e-06, 7.2426e-07,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.1972e-06, 6.3683e-06, 9.5214e-07,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.6350e-04, 2.5483e-04, 8.9959e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[3.9215e-05, 7.0059e-06, 7.6602e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.1559e-05, 3.3166e-06, 3.8001e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.3498e-06, 4.6072e-08, 7.4818e-08,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.1545e-08, 7.8893e-12, 1.3274e-11,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[4.9032e-08, 2.2185e-11, 3.4002e-11,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[7.6939e-05, 7.6791e-04, 7.7877e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[1.8763e-05, 1.6623e-03, 1.6342e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.6260e-05, 1.1345e-03, 1.1908e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.3649e-04, 2.0726e-04, 2.6364e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.3020e-06, 2.9196e-05, 3.7811e-05,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.8384e-06, 8.4010e-05, 1.0313e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.2548e-05, 1.5107e-03, 1.2849e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]]]]), decoder_attention=tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.5989e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.4248e-04, 3.7572e-04, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.3486e-06, 2.4105e-06, 2.1119e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.2772e-06, 2.4259e-06, 2.1039e-04,  ..., 3.9572e-03,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.1179e-06, 6.1920e-06, 7.8274e-04,  ..., 2.9845e-04,\n",
       "           2.6758e-04, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[9.0847e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[8.2978e-03, 9.8115e-03, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[9.2691e-05, 1.2634e-04, 1.4583e-04,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.1477e-05, 8.0504e-05, 9.3713e-05,  ..., 2.3048e-04,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.4079e-04, 1.9844e-04, 2.0760e-04,  ..., 3.4149e-05,\n",
       "           5.2518e-05, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.6072e-07, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.1600e-07, 4.1851e-07, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.2716e-03, 4.6489e-03, 4.8072e-03,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[4.7691e-03, 5.2301e-03, 5.5657e-03,  ..., 2.3482e-05,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.8626e-07, 4.0354e-07, 4.7024e-07,  ..., 1.5028e-03,\n",
       "           1.4153e-03, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.3524e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.5557e-08, 4.3757e-08, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.4321e-10, 1.6229e-09, 6.5176e-08,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[8.1625e-10, 2.7867e-09, 8.1387e-08,  ..., 1.1422e-06,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.8944e-03, 4.4046e-03, 5.2216e-05,  ..., 7.0333e-06,\n",
       "           8.8177e-06, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.0691e-05, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[7.5546e-05, 3.4813e-05, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.3934e-08, 4.6823e-09, 3.2535e-13,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.4260e-08, 5.6020e-09, 1.1483e-12,  ..., 1.9908e-09,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.6576e-07, 1.6655e-07, 1.0748e-05,  ..., 8.4678e-08,\n",
       "           1.8893e-07, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[4.2815e-05, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.1846e-04, 1.4658e-04, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.0195e-05, 8.6153e-06, 1.0708e-06,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.3199e-05, 1.1814e-05, 2.6615e-06,  ..., 3.2333e-05,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[2.4623e-05, 3.9508e-05, 1.0111e-04,  ..., 1.0195e-05,\n",
       "           1.5272e-05, 0.0000e+00]]]]), static_variables=tensor([[[0.9409, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0206]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0206]],\n",
       "\n",
       "        [[0.9409, 0.0060, 0.0323, 0.0207]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0206]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0323, 0.0209]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9409, 0.0060, 0.0323, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9410, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0209]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0209]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0323, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0060, 0.0324, 0.0207]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0323, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0323, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0323, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0323, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0059, 0.0324, 0.0208]],\n",
       "\n",
       "        [[0.9409, 0.0060, 0.0323, 0.0208]]]), encoder_variables=tensor([[[[0.1296, 0.2756, 0.2336, 0.0078, 0.3533]],\n",
       "\n",
       "         [[0.1296, 0.2756, 0.2336, 0.0078, 0.3533]],\n",
       "\n",
       "         [[0.1296, 0.2756, 0.2336, 0.0078, 0.3533]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.2956, 0.1014, 0.1911, 0.3003, 0.1117]],\n",
       "\n",
       "         [[0.2956, 0.1014, 0.1911, 0.3003, 0.1117]],\n",
       "\n",
       "         [[0.2956, 0.1014, 0.1911, 0.3003, 0.1117]]],\n",
       "\n",
       "\n",
       "        [[[0.1298, 0.2757, 0.2339, 0.0078, 0.3528]],\n",
       "\n",
       "         [[0.1297, 0.2756, 0.2338, 0.0078, 0.3531]],\n",
       "\n",
       "         [[0.1294, 0.2755, 0.2334, 0.0078, 0.3539]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.3338, 0.1145, 0.2017, 0.2331, 0.1168]],\n",
       "\n",
       "         [[0.3338, 0.1145, 0.2017, 0.2331, 0.1168]],\n",
       "\n",
       "         [[0.3338, 0.1145, 0.2017, 0.2331, 0.1168]]],\n",
       "\n",
       "\n",
       "        [[[0.1296, 0.2756, 0.2336, 0.0078, 0.3534]],\n",
       "\n",
       "         [[0.1296, 0.2756, 0.2337, 0.0078, 0.3533]],\n",
       "\n",
       "         [[0.1296, 0.2756, 0.2337, 0.0078, 0.3533]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0741, 0.1796, 0.4994, 0.0099, 0.2371]],\n",
       "\n",
       "         [[0.0741, 0.1796, 0.4994, 0.0099, 0.2371]],\n",
       "\n",
       "         [[0.0741, 0.1796, 0.4994, 0.0099, 0.2371]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.1297, 0.2755, 0.2338, 0.0078, 0.3532]],\n",
       "\n",
       "         [[0.1297, 0.2755, 0.2338, 0.0078, 0.3532]],\n",
       "\n",
       "         [[0.1296, 0.2755, 0.2337, 0.0078, 0.3534]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.2773, 0.2223, 0.1773, 0.0134, 0.3098]],\n",
       "\n",
       "         [[0.2773, 0.2223, 0.1773, 0.0134, 0.3098]],\n",
       "\n",
       "         [[0.2773, 0.2223, 0.1773, 0.0134, 0.3098]]],\n",
       "\n",
       "\n",
       "        [[[0.1296, 0.2757, 0.2336, 0.0078, 0.3533]],\n",
       "\n",
       "         [[0.1296, 0.2757, 0.2336, 0.0078, 0.3533]],\n",
       "\n",
       "         [[0.1296, 0.2757, 0.2337, 0.0078, 0.3532]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.2218, 0.0764, 0.1723, 0.4234, 0.1062]],\n",
       "\n",
       "         [[0.2218, 0.0764, 0.1723, 0.4234, 0.1062]],\n",
       "\n",
       "         [[0.2218, 0.0764, 0.1723, 0.4234, 0.1062]]],\n",
       "\n",
       "\n",
       "        [[[0.1297, 0.2756, 0.2337, 0.0078, 0.3532]],\n",
       "\n",
       "         [[0.1297, 0.2756, 0.2337, 0.0078, 0.3532]],\n",
       "\n",
       "         [[0.1297, 0.2756, 0.2337, 0.0078, 0.3531]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0789, 0.0414, 0.4137, 0.2967, 0.1694]],\n",
       "\n",
       "         [[0.0789, 0.0414, 0.4137, 0.2967, 0.1694]],\n",
       "\n",
       "         [[0.0789, 0.0414, 0.4137, 0.2967, 0.1694]]]]), decoder_variables=tensor([[[[0.0636, 0.3502, 0.1617, 0.4245]],\n",
       "\n",
       "         [[0.0599, 0.3395, 0.1725, 0.4281]],\n",
       "\n",
       "         [[0.0556, 0.3201, 0.1915, 0.4328]],\n",
       "\n",
       "         [[0.0554, 0.3180, 0.1933, 0.4333]],\n",
       "\n",
       "         [[0.0686, 0.3601, 0.1511, 0.4202]],\n",
       "\n",
       "         [[0.0685, 0.3596, 0.1515, 0.4205]],\n",
       "\n",
       "         [[0.2246, 0.1240, 0.5395, 0.1119]]],\n",
       "\n",
       "\n",
       "        [[[0.4787, 0.1198, 0.3312, 0.0703]],\n",
       "\n",
       "         [[0.4943, 0.1199, 0.3192, 0.0667]],\n",
       "\n",
       "         [[0.5078, 0.1199, 0.3080, 0.0644]],\n",
       "\n",
       "         [[0.5175, 0.1198, 0.2994, 0.0633]],\n",
       "\n",
       "         [[0.5282, 0.1196, 0.2894, 0.0628]],\n",
       "\n",
       "         [[0.5349, 0.1193, 0.2830, 0.0628]],\n",
       "\n",
       "         [[0.5166, 0.1189, 0.2963, 0.0682]]],\n",
       "\n",
       "\n",
       "        [[[0.0698, 0.3645, 0.1485, 0.4172]],\n",
       "\n",
       "         [[0.0693, 0.3626, 0.1496, 0.4185]],\n",
       "\n",
       "         [[0.0685, 0.3598, 0.1514, 0.4203]],\n",
       "\n",
       "         [[0.0682, 0.3588, 0.1520, 0.4210]],\n",
       "\n",
       "         [[0.0655, 0.3504, 0.1586, 0.4256]],\n",
       "\n",
       "         [[0.0653, 0.3496, 0.1592, 0.4259]],\n",
       "\n",
       "         [[0.5960, 0.1169, 0.2049, 0.0822]]],\n",
       "\n",
       "\n",
       "        [[[0.0694, 0.3637, 0.1491, 0.4178]],\n",
       "\n",
       "         [[0.0677, 0.3576, 0.1532, 0.4215]],\n",
       "\n",
       "         [[0.0646, 0.3487, 0.1605, 0.4261]],\n",
       "\n",
       "         [[0.0644, 0.3479, 0.1612, 0.4265]],\n",
       "\n",
       "         [[0.0712, 0.3695, 0.1454, 0.4138]],\n",
       "\n",
       "         [[0.0712, 0.3692, 0.1456, 0.4141]],\n",
       "\n",
       "         [[0.6112, 0.1170, 0.1897, 0.0820]]],\n",
       "\n",
       "\n",
       "        [[[0.0653, 0.3538, 0.1578, 0.4231]],\n",
       "\n",
       "         [[0.0620, 0.3446, 0.1666, 0.4268]],\n",
       "\n",
       "         [[0.0575, 0.3292, 0.1821, 0.4311]],\n",
       "\n",
       "         [[0.0572, 0.3277, 0.1835, 0.4316]],\n",
       "\n",
       "         [[0.0694, 0.3625, 0.1494, 0.4186]],\n",
       "\n",
       "         [[0.0693, 0.3621, 0.1497, 0.4190]],\n",
       "\n",
       "         [[0.2254, 0.1239, 0.5395, 0.1112]]],\n",
       "\n",
       "\n",
       "        [[[0.0757, 0.3853, 0.1372, 0.4018]],\n",
       "\n",
       "         [[0.0760, 0.3842, 0.1371, 0.4028]],\n",
       "\n",
       "         [[0.0763, 0.3827, 0.1370, 0.4040]],\n",
       "\n",
       "         [[0.0763, 0.3825, 0.1370, 0.4042]],\n",
       "\n",
       "         [[0.0753, 0.3863, 0.1375, 0.4010]],\n",
       "\n",
       "         [[0.0753, 0.3862, 0.1375, 0.4011]],\n",
       "\n",
       "         [[0.0770, 0.3728, 0.1381, 0.4121]]],\n",
       "\n",
       "\n",
       "        [[[0.0571, 0.3333, 0.1812, 0.4284]],\n",
       "\n",
       "         [[0.0538, 0.3095, 0.2031, 0.4336]],\n",
       "\n",
       "         [[0.0605, 0.2364, 0.2700, 0.4331]],\n",
       "\n",
       "         [[0.0646, 0.2233, 0.2859, 0.4262]],\n",
       "\n",
       "         [[0.0647, 0.3505, 0.1598, 0.4249]],\n",
       "\n",
       "         [[0.0644, 0.3498, 0.1605, 0.4253]],\n",
       "\n",
       "         [[0.4349, 0.1220, 0.3778, 0.0652]]],\n",
       "\n",
       "\n",
       "        [[[0.0750, 0.3852, 0.1379, 0.4019]],\n",
       "\n",
       "         [[0.0753, 0.3841, 0.1378, 0.4028]],\n",
       "\n",
       "         [[0.0756, 0.3826, 0.1377, 0.4040]],\n",
       "\n",
       "         [[0.0756, 0.3825, 0.1378, 0.4042]],\n",
       "\n",
       "         [[0.0747, 0.3862, 0.1381, 0.4010]],\n",
       "\n",
       "         [[0.0747, 0.3861, 0.1381, 0.4011]],\n",
       "\n",
       "         [[0.0759, 0.3729, 0.1392, 0.4119]]],\n",
       "\n",
       "\n",
       "        [[[0.3764, 0.1229, 0.3860, 0.1148]],\n",
       "\n",
       "         [[0.3754, 0.1230, 0.3860, 0.1156]],\n",
       "\n",
       "         [[0.3683, 0.1230, 0.3935, 0.1152]],\n",
       "\n",
       "         [[0.3674, 0.1231, 0.3932, 0.1163]],\n",
       "\n",
       "         [[0.2016, 0.1412, 0.4301, 0.2271]],\n",
       "\n",
       "         [[0.2218, 0.1377, 0.4321, 0.2084]],\n",
       "\n",
       "         [[0.3767, 0.1212, 0.4161, 0.0859]]],\n",
       "\n",
       "\n",
       "        [[[0.0659, 0.3550, 0.1566, 0.4225]],\n",
       "\n",
       "         [[0.0627, 0.3463, 0.1647, 0.4263]],\n",
       "\n",
       "         [[0.0583, 0.3320, 0.1791, 0.4306]],\n",
       "\n",
       "         [[0.0580, 0.3306, 0.1804, 0.4310]],\n",
       "\n",
       "         [[0.0697, 0.3634, 0.1489, 0.4181]],\n",
       "\n",
       "         [[0.0696, 0.3629, 0.1491, 0.4184]],\n",
       "\n",
       "         [[0.2350, 0.1236, 0.5337, 0.1077]]],\n",
       "\n",
       "\n",
       "        [[[0.0747, 0.3784, 0.1395, 0.4074]],\n",
       "\n",
       "         [[0.0749, 0.3761, 0.1397, 0.4092]],\n",
       "\n",
       "         [[0.0750, 0.3731, 0.1402, 0.4117]],\n",
       "\n",
       "         [[0.0750, 0.3727, 0.1403, 0.4121]],\n",
       "\n",
       "         [[0.0745, 0.3811, 0.1392, 0.4052]],\n",
       "\n",
       "         [[0.0745, 0.3809, 0.1392, 0.4053]],\n",
       "\n",
       "         [[0.0680, 0.3504, 0.1547, 0.4269]]],\n",
       "\n",
       "\n",
       "        [[[0.0730, 0.3809, 0.1409, 0.4051]],\n",
       "\n",
       "         [[0.0732, 0.3792, 0.1411, 0.4066]],\n",
       "\n",
       "         [[0.0733, 0.3769, 0.1414, 0.4084]],\n",
       "\n",
       "         [[0.0733, 0.3766, 0.1414, 0.4087]],\n",
       "\n",
       "         [[0.0730, 0.3828, 0.1406, 0.4036]],\n",
       "\n",
       "         [[0.0730, 0.3827, 0.1406, 0.4037]],\n",
       "\n",
       "         [[0.0723, 0.3605, 0.1462, 0.4210]]],\n",
       "\n",
       "\n",
       "        [[[0.0535, 0.2940, 0.2158, 0.4367]],\n",
       "\n",
       "         [[0.0801, 0.1999, 0.3103, 0.4098]],\n",
       "\n",
       "         [[0.2975, 0.1287, 0.4191, 0.1546]],\n",
       "\n",
       "         [[0.3059, 0.1280, 0.4161, 0.1500]],\n",
       "\n",
       "         [[0.0589, 0.3362, 0.1760, 0.4289]],\n",
       "\n",
       "         [[0.0585, 0.3350, 0.1773, 0.4292]],\n",
       "\n",
       "         [[0.2664, 0.1226, 0.5160, 0.0950]]],\n",
       "\n",
       "\n",
       "        [[[0.0675, 0.3586, 0.1531, 0.4207]],\n",
       "\n",
       "         [[0.0648, 0.3512, 0.1594, 0.4246]],\n",
       "\n",
       "         [[0.0608, 0.3395, 0.1706, 0.4290]],\n",
       "\n",
       "         [[0.0605, 0.3384, 0.1717, 0.4294]],\n",
       "\n",
       "         [[0.0703, 0.3659, 0.1474, 0.4164]],\n",
       "\n",
       "         [[0.0703, 0.3655, 0.1475, 0.4167]],\n",
       "\n",
       "         [[0.2405, 0.1233, 0.5321, 0.1042]]],\n",
       "\n",
       "\n",
       "        [[[0.0699, 0.3653, 0.1481, 0.4167]],\n",
       "\n",
       "         [[0.0696, 0.3638, 0.1489, 0.4178]],\n",
       "\n",
       "         [[0.0691, 0.3618, 0.1501, 0.4190]],\n",
       "\n",
       "         [[0.0681, 0.3585, 0.1523, 0.4211]],\n",
       "\n",
       "         [[0.0653, 0.3499, 0.1590, 0.4257]],\n",
       "\n",
       "         [[0.0651, 0.3492, 0.1596, 0.4261]],\n",
       "\n",
       "         [[0.3416, 0.1219, 0.4416, 0.0949]]],\n",
       "\n",
       "\n",
       "        [[[0.0661, 0.3538, 0.1567, 0.4235]],\n",
       "\n",
       "         [[0.0656, 0.3525, 0.1578, 0.4242]],\n",
       "\n",
       "         [[0.0621, 0.3424, 0.1671, 0.4284]],\n",
       "\n",
       "         [[0.0616, 0.3410, 0.1685, 0.4289]],\n",
       "\n",
       "         [[0.0713, 0.3678, 0.1457, 0.4152]],\n",
       "\n",
       "         [[0.0712, 0.3674, 0.1459, 0.4155]],\n",
       "\n",
       "         [[0.0479, 0.2539, 0.2901, 0.4082]]],\n",
       "\n",
       "\n",
       "        [[[0.0753, 0.3837, 0.1378, 0.4031]],\n",
       "\n",
       "         [[0.0756, 0.3823, 0.1378, 0.4043]],\n",
       "\n",
       "         [[0.0760, 0.3805, 0.1377, 0.4058]],\n",
       "\n",
       "         [[0.0760, 0.3803, 0.1377, 0.4060]],\n",
       "\n",
       "         [[0.0750, 0.3850, 0.1380, 0.4020]],\n",
       "\n",
       "         [[0.0750, 0.3849, 0.1380, 0.4021]],\n",
       "\n",
       "         [[0.0756, 0.3678, 0.1406, 0.4159]]],\n",
       "\n",
       "\n",
       "        [[[0.0765, 0.3834, 0.1366, 0.4034]],\n",
       "\n",
       "         [[0.0769, 0.3819, 0.1365, 0.4047]],\n",
       "\n",
       "         [[0.0774, 0.3800, 0.1364, 0.4063]],\n",
       "\n",
       "         [[0.0774, 0.3797, 0.1364, 0.4065]],\n",
       "\n",
       "         [[0.0760, 0.3849, 0.1369, 0.4022]],\n",
       "\n",
       "         [[0.0760, 0.3847, 0.1369, 0.4023]],\n",
       "\n",
       "         [[0.0770, 0.3676, 0.1392, 0.4162]]],\n",
       "\n",
       "\n",
       "        [[[0.0651, 0.3532, 0.1584, 0.4233]],\n",
       "\n",
       "         [[0.0616, 0.3438, 0.1675, 0.4271]],\n",
       "\n",
       "         [[0.0572, 0.3279, 0.1835, 0.4314]],\n",
       "\n",
       "         [[0.0569, 0.3262, 0.1850, 0.4318]],\n",
       "\n",
       "         [[0.0693, 0.3621, 0.1497, 0.4189]],\n",
       "\n",
       "         [[0.0692, 0.3616, 0.1499, 0.4192]],\n",
       "\n",
       "         [[0.2431, 0.1233, 0.5293, 0.1044]]],\n",
       "\n",
       "\n",
       "        [[[0.0670, 0.3564, 0.1544, 0.4221]],\n",
       "\n",
       "         [[0.0667, 0.3553, 0.1553, 0.4228]],\n",
       "\n",
       "         [[0.0632, 0.3455, 0.1640, 0.4273]],\n",
       "\n",
       "         [[0.0629, 0.3445, 0.1649, 0.4277]],\n",
       "\n",
       "         [[0.0708, 0.3682, 0.1462, 0.4148]],\n",
       "\n",
       "         [[0.0708, 0.3678, 0.1464, 0.4151]],\n",
       "\n",
       "         [[0.2306, 0.1237, 0.5364, 0.1093]]],\n",
       "\n",
       "\n",
       "        [[[0.0621, 0.3469, 0.1655, 0.4255]],\n",
       "\n",
       "         [[0.0582, 0.3345, 0.1781, 0.4291]],\n",
       "\n",
       "         [[0.0544, 0.3102, 0.2008, 0.4345]],\n",
       "\n",
       "         [[0.0543, 0.3074, 0.2031, 0.4352]],\n",
       "\n",
       "         [[0.0679, 0.3580, 0.1528, 0.4214]],\n",
       "\n",
       "         [[0.0677, 0.3574, 0.1532, 0.4217]],\n",
       "\n",
       "         [[0.1106, 0.1419, 0.5422, 0.2052]]],\n",
       "\n",
       "\n",
       "        [[[0.0725, 0.3762, 0.1425, 0.4089]],\n",
       "\n",
       "         [[0.0724, 0.3735, 0.1430, 0.4110]],\n",
       "\n",
       "         [[0.0723, 0.3700, 0.1440, 0.4137]],\n",
       "\n",
       "         [[0.0722, 0.3695, 0.1442, 0.4141]],\n",
       "\n",
       "         [[0.0727, 0.3794, 0.1416, 0.4063]],\n",
       "\n",
       "         [[0.0727, 0.3792, 0.1416, 0.4065]],\n",
       "\n",
       "         [[0.0624, 0.3409, 0.1672, 0.4296]]],\n",
       "\n",
       "\n",
       "        [[[0.0731, 0.3775, 0.1415, 0.4080]],\n",
       "\n",
       "         [[0.0732, 0.3751, 0.1419, 0.4099]],\n",
       "\n",
       "         [[0.0732, 0.3718, 0.1425, 0.4125]],\n",
       "\n",
       "         [[0.0731, 0.3714, 0.1427, 0.4128]],\n",
       "\n",
       "         [[0.0732, 0.3803, 0.1408, 0.4056]],\n",
       "\n",
       "         [[0.0732, 0.3802, 0.1408, 0.4058]],\n",
       "\n",
       "         [[0.0651, 0.3462, 0.1606, 0.4281]]],\n",
       "\n",
       "\n",
       "        [[[0.0731, 0.3794, 0.1411, 0.4064]],\n",
       "\n",
       "         [[0.0732, 0.3774, 0.1413, 0.4080]],\n",
       "\n",
       "         [[0.0733, 0.3747, 0.1417, 0.4102]],\n",
       "\n",
       "         [[0.0733, 0.3743, 0.1418, 0.4105]],\n",
       "\n",
       "         [[0.0731, 0.3817, 0.1406, 0.4045]],\n",
       "\n",
       "         [[0.0731, 0.3816, 0.1407, 0.4046]],\n",
       "\n",
       "         [[0.0685, 0.3541, 0.1529, 0.4245]]],\n",
       "\n",
       "\n",
       "        [[[0.0558, 0.3273, 0.1873, 0.4296]],\n",
       "\n",
       "         [[0.0536, 0.2971, 0.2128, 0.4364]],\n",
       "\n",
       "         [[0.0793, 0.1991, 0.3151, 0.4065]],\n",
       "\n",
       "         [[0.0897, 0.1877, 0.3336, 0.3890]],\n",
       "\n",
       "         [[0.0633, 0.3473, 0.1633, 0.4261]],\n",
       "\n",
       "         [[0.0630, 0.3465, 0.1641, 0.4264]],\n",
       "\n",
       "         [[0.2406, 0.1234, 0.5304, 0.1056]]],\n",
       "\n",
       "\n",
       "        [[[0.0742, 0.3835, 0.1391, 0.4032]],\n",
       "\n",
       "         [[0.0744, 0.3822, 0.1391, 0.4043]],\n",
       "\n",
       "         [[0.0747, 0.3804, 0.1392, 0.4058]],\n",
       "\n",
       "         [[0.0747, 0.3802, 0.1392, 0.4059]],\n",
       "\n",
       "         [[0.0740, 0.3848, 0.1391, 0.4021]],\n",
       "\n",
       "         [[0.0740, 0.3847, 0.1391, 0.4022]],\n",
       "\n",
       "         [[0.0741, 0.3682, 0.1422, 0.4155]]],\n",
       "\n",
       "\n",
       "        [[[0.0706, 0.3681, 0.1465, 0.4148]],\n",
       "\n",
       "         [[0.0696, 0.3632, 0.1490, 0.4182]],\n",
       "\n",
       "         [[0.0677, 0.3561, 0.1536, 0.4226]],\n",
       "\n",
       "         [[0.0675, 0.3555, 0.1540, 0.4230]],\n",
       "\n",
       "         [[0.0715, 0.3727, 0.1444, 0.4114]],\n",
       "\n",
       "         [[0.0715, 0.3724, 0.1445, 0.4117]],\n",
       "\n",
       "         [[0.1760, 0.1272, 0.5616, 0.1353]]],\n",
       "\n",
       "\n",
       "        [[[0.0638, 0.3505, 0.1614, 0.4244]],\n",
       "\n",
       "         [[0.0601, 0.3399, 0.1720, 0.4280]],\n",
       "\n",
       "         [[0.0558, 0.3209, 0.1907, 0.4326]],\n",
       "\n",
       "         [[0.0555, 0.3189, 0.1925, 0.4331]],\n",
       "\n",
       "         [[0.0687, 0.3603, 0.1510, 0.4200]],\n",
       "\n",
       "         [[0.0686, 0.3598, 0.1513, 0.4204]],\n",
       "\n",
       "         [[0.2383, 0.1234, 0.5319, 0.1064]]],\n",
       "\n",
       "\n",
       "        [[[0.0686, 0.3613, 0.1509, 0.4192]],\n",
       "\n",
       "         [[0.0664, 0.3546, 0.1559, 0.4231]],\n",
       "\n",
       "         [[0.0628, 0.3446, 0.1650, 0.4276]],\n",
       "\n",
       "         [[0.0626, 0.3436, 0.1658, 0.4280]],\n",
       "\n",
       "         [[0.0708, 0.3678, 0.1464, 0.4150]],\n",
       "\n",
       "         [[0.0707, 0.3674, 0.1465, 0.4153]],\n",
       "\n",
       "         [[0.2325, 0.1237, 0.5352, 0.1087]]]]), decoder_lengths=tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7]), encoder_lengths=tensor([1037, 1019,  997, 1029, 1039, 1040, 1044, 1022, 1034, 1030, 1038, 1029,\n",
       "        1033, 1053,  958, 1031, 1019, 1041, 1026, 1020, 1025, 1026, 1025, 1028,\n",
       "        1040, 1030, 1018, 1024, 1043]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions, x = tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "raw_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f54648b5-4bc1-4079-8fbe-8ac057d7a38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lightning_logs/version_0/metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load training logs\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlightning_logs/version_0/metrics.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot validation vs training loss\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m], logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss_step\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lightning_logs/version_0/metrics.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load training logs\n",
    "logs = pd.read_csv(\"lightning_logs/version_0/metrics.csv\")\n",
    "\n",
    "# Plot validation vs training loss\n",
    "plt.plot(logs[\"epoch\"], logs[\"train_loss_step\"], label=\"Train Loss\")\n",
    "plt.plot(logs[\"epoch\"], logs[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bb479c2-e034-4e82-9db1-5d7ff7b60d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /Users/fjung/dev/ticket-price-forecast/lightning_logs/version_2/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LR finder stopped early after 5040 steps due to diverging loss.\n",
      "Restoring states from the checkpoint path at /Users/fjung/dev/ticket-price-forecast/.lr_find_80555e4c-b559-4793-ad74-2c551ca97fa2.ckpt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'radam_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuner\n\u001b[0;32m----> 3\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39msuggestion()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m fig \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mplot(show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, suggest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/tuner/tuning.py:267\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr)\u001b[0m\n\u001b[1;32m    264\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mauto_lr_find \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1097\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_hyperparams()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1394\u001b[0m, in \u001b[0;36mTrainer._call_callback_hooks\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m   1393\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1394\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1398\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/callbacks/lr_finder.py:122\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_fit_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/callbacks/lr_finder.py:107\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlr_find\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 107\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_lr \u001b[38;5;241m=\u001b[39m \u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mearly_stop_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_early_stop_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mupdate_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_exit:\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m _TunerExitException()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/tuner/lr_finder.py:273\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr)\u001b[0m\n\u001b[1;32m    270\u001b[0m         log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning rate set to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Restore initial state of model\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mremove_checkpoint(ckpt_path)\n\u001b[1;32m    275\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# reset restarting flag as checkpoint restoring sets it to True\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:234\u001b[0m, in \u001b[0;36mCheckpointConnector.restore\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_callbacks()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# restore training state\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_training_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:286\u001b[0m, in \u001b[0;36mCheckpointConnector.restore_training_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# restore optimizers and schedulers state\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_optimizers_and_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:382\u001b[0m, in \u001b[0;36mCheckpointConnector.restore_optimizers_and_schedulers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_states\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_checkpoint:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to restore optimizer state but checkpoint contains only the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This is probably due to `ModelCheckpoint.save_weights_only` being set to `True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m         )\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_schedulers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_checkpoint:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to restore learning rate scheduler state but checkpoint contains only the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This is probably due to `ModelCheckpoint.save_weights_only` being set to `True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:397\u001b[0m, in \u001b[0;36mCheckpointConnector.restore_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# restore the optimizers\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_optimizer_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loaded_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:368\u001b[0m, in \u001b[0;36mStrategy.load_optimizer_state_dict\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m    366\u001b[0m optimizer_states \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_states\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optimizer, opt_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, optimizer_states):\n\u001b[0;32m--> 368\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     _optimizer_to_device(optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:244\u001b[0m, in \u001b[0;36mOptimizer.load_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_group\n\u001b[1;32m    242\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    243\u001b[0m     update_group(g, ng) \u001b[38;5;28;01mfor\u001b[39;00m g, ng \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(groups, saved_groups)]\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_groups\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_groups\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_forecasting/optim.py:133\u001b[0m, in \u001b[0;36mRanger.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__setstate__(state)\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradam_buffer \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mradam_buffer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'radam_buffer'"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f05f32cc-5293-469a-8c8e-147a678cf8aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tuner' from 'pytorch_lightning' (/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuner\n\u001b[1;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m Tuner(trainer)\u001b[38;5;241m.\u001b[39mlr_find(\n\u001b[1;32m      4\u001b[0m     tft,\n\u001b[1;32m      5\u001b[0m     train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39msuggestion()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tuner' from 'pytorch_lightning' (/Users/fjung/miniconda3/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Predict using the validation set\n",
    "raw_predictions, x = tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "# Plot one example prediction\n",
    "tft.plot_prediction(x, raw_predictions, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed9dc4-86d1-40f5-95e5-ea0a37013202",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7de559a2-1344-49c0-a4e2-3b73f3c41b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from datetime import timedelta\n",
    "\n",
    "def predict_future_prices(\n",
    "    model,\n",
    "    training_dataset,\n",
    "    route: str,\n",
    "    start_date: pd.Timestamp,\n",
    "    days_ahead: int = 7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict future best prices for a given route and starting date.\n",
    "\n",
    "    Parameters:\n",
    "        model (TemporalFusionTransformer): trained TFT model\n",
    "        training_dataset (TimeSeriesDataSet): original training dataset (for from_dataset)\n",
    "        route (str): route code, e.g., \"CGK_DPS\"\n",
    "        start_date (pd.Timestamp): date to start forecasting from\n",
    "        days_ahead (int): number of days to forecast\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with predictions\n",
    "    \"\"\"\n",
    "\n",
    "    assert route in df[\"route\"].cat.categories, f\"Unknown route: {route}\"\n",
    "    base_date = df[\"depart_date\"].min()\n",
    "\n",
    "\n",
    "    # Get last known entry for the route\n",
    "    past_data = training_dataset.data[training_dataset.data[\"route\"] == route].copy()\n",
    "    past_data = past_data.sort_values(\"depart_date\")\n",
    "    last_known_row = past_data.iloc[-1]\n",
    "\n",
    "    # Use original DataFrame to get categories and reference\n",
    "    future_dates = [start_date + timedelta(days=i) for i in range(days_ahead)]\n",
    "    future_df = pd.DataFrame({\n",
    "        \"depart_date\": future_dates,\n",
    "        \"calendar_day\": [(d - base_date).days for d in future_dates],\n",
    "        \"extract_date\": last_known_row[\"extract_date\"],\n",
    "        \"route\": route,\n",
    "        \"airport_from\": last_known_row[\"airport_from\"],\n",
    "        \"airport_to\": last_known_row[\"airport_to\"],\n",
    "        \"distance_km\": last_known_row[\"distance_km\"],\n",
    "        \"flight_time_hour\": last_known_row[\"flight_time_hour\"],\n",
    "        \"days_to_departure\": [(d - last_known_row[\"extract_date\"]).days for d in future_dates],\n",
    "        \"weekday\": [d.strftime(\"%A\") for d in future_dates],\n",
    "        \"month\": [d.strftime(\"%B\") for d in future_dates],\n",
    "    })\n",
    "    \n",
    "    # Ensure categorical types\n",
    "    future_df[\"weekday\"] = pd.Categorical(future_df[\"weekday\"], categories=df[\"weekday\"].cat.categories)\n",
    "    future_df[\"month\"] = pd.Categorical(future_df[\"month\"], categories=df[\"month\"].cat.categories)\n",
    "    future_df[\"route\"] = pd.Categorical([route] * days_ahead, categories=df[\"route\"].cat.categories)\n",
    "\n",
    "\n",
    "    # Create prediction dataset\n",
    "    prediction_dataset = TimeSeriesDataSet.from_dataset(training_dataset, future_df, predict=True, stop_randomization=True)\n",
    "\n",
    "    # Predict\n",
    "    raw_preds, x = model.predict(prediction_dataset, mode=\"raw\", return_x=True)\n",
    "    y_pred = model.to_prediction(raw_preds)\n",
    "\n",
    "    # Return forecast as DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"date\": future_df[\"depart_date\"],\n",
    "        \"predicted_best_price\": y_pred.flatten()\n",
    "    })\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0ee3401-7ca7-4a56-95b7-6dea35d474c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'route'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m future_prices \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_future_prices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCGK_DPS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-08-01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdays_ahead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m future_prices\n",
      "Cell \u001b[0;32mIn[45], line 30\u001b[0m, in \u001b[0;36mpredict_future_prices\u001b[0;34m(model, training_dataset, route, start_date, days_ahead)\u001b[0m\n\u001b[1;32m     26\u001b[0m base_date \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Get last known entry for the route\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m past_data \u001b[38;5;241m=\u001b[39m training_dataset\u001b[38;5;241m.\u001b[39mdata[\u001b[43mtraining_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m route]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     31\u001b[0m past_data \u001b[38;5;241m=\u001b[39m past_data\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m last_known_row \u001b[38;5;241m=\u001b[39m past_data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'route'"
     ]
    }
   ],
   "source": [
    "future_prices = predict_future_prices(\n",
    "    model=tft,\n",
    "    training_dataset=training,\n",
    "    route=\"CGK_DPS\",\n",
    "    start_date=pd.Timestamp(\"2023-08-01\"),\n",
    "    days_ahead=7\n",
    ")\n",
    "future_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa68f2-9cd5-4396-af93-176e0d941287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
